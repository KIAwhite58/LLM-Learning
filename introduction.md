学习路径
第一阶段：基础理论入门
目标：了解大模型的基本概念和背景，为后续学习打下坚实基础。
人工智能演进与大模型兴起：回顾人工智能的发展历程，了解大模型在其中的地位和作用。
大模型定义及通用人工智能定义：明确大模型的内涵和外延，探讨通用人工智能的实现路径。
GPT模型的发展历程：梳理GPT系列模型的技术演进，了解其在我国的发展现状。
第二阶段：核心技术解析
目标：深入学习大模型的关键技术和工作原理，提升理论素养。
算法的创新、计算能力的提升：探讨大模型背后的算法原理，了解计算能力对模型性能的影响。
数据的可用性与规模性、软件与工具的进步：分析大数据在大模型中的作用，学习相关软件和工具的使用。
生成式模型与大语言模型：对比分析生成式模型与大语言模型的优缺点，掌握各自的应用场景。
Transformer架构解析：深入研究Transformer架构，理解其在大模型中的核心地位。
预训练、SFT、RLHF：学习大模型的训练方法，掌握预训练、SFT（监督式微调）和RLHF（强化学习与人类反馈）等技术。
第三阶段：编程基础与工具使用
目标：掌握大模型开发所需的编程基础和工具，为实战项目做好准备。
Python编程基础：学习Python基本语法、数据结构、函数等。
Python常用库和工具：熟悉Numpy、Pandas、TensorFlow、PyTorch等库的使用。
提示工程基础：掌握提示工程的基本原理和技巧，提高编程效率。
第四阶段：实战项目与案例分析
目标：通过实战项目深化理论知识和提升应用能力。
实战项目一：基于提示工程的代码生成。
实战项目二：基于大模型的文档智能助手。
实战项目三：基于大模型的医学命名实体识别系统。
案例分析：针对每个实战项目进行详细的分析和讨论，总结经验教训。
第五阶段：高级应用开发
目标：掌握大模型的高级应用开发技能，拓宽应用领域。
大模型API应用开发：学习如何使用大模型API进行应用开发。
RAG (Retrieval-Augmented Generation)：了解基于检索增强的生成技术。
向量检索与向量数据库：掌握向量检索技术，了解向量数据库的应用。
LangChain、Agents、AutoGPT：学习大模型在自动化、智能体等领域的应用。
第六阶段：模型微调与私有化部署
目标：学习如何对大模型进行微调并私有化部署，满足个性化需求。
私有化部署的必要性：分析私有化部署的优势和场景。
HuggingFace开源社区的使用：学习如何利用HuggingFace开源社区进行模型微调。
模型微调的意义和常见技术：掌握模型微调的方法和技巧。
第七阶段：前沿技术探索
目标：探索大模型领域的前沿技术和未来趋势，为行业发展贡献力量。
多模态模型：了解多模态模型的发展现状和应用。
参数高效微调技术：学习参数高效微调的方法，提高模型训练效率。
深度学习框架比较：对比分析不同深度学习框架的特点和适用场景。
大模型评估和benchmarking：掌握大模型评估方法，了解行业benchmarking标准。
学习笔记
第一阶段：基础理论入门
人工智能演进与大模型兴起：人工智能经历了从规则-based到机器学习再到深度学习的演进过程，大模型是深度学习的重要成果之一。
大模型定义及通用人工智能定义：大模型是指具有大量参数和复杂结构的深度学习模型，通用人工智能是指能够像人类一样处理各种任务的智能系统。
GPT模型的发展历程：GPT系列模型从GPT-1到GPT-4，参数规模和性能不断提升，推动了自然语言处理领域的发展。
第二阶段：核心技术解析
算法的创新、计算能力的提升：大模型的算法创新包括Transformer架构的引入，计算能力的提升主要依赖于GPU和分布式计算。
数据的可用性与规模性、软件与工具的进步：大数据的可用性和规模性是大模型训练的基础，软件与工具的进步如PyTorch和TensorFlow等框架的出现，为大模型的开发提供了便利。
生成式模型与大语言模型：生成式模型能够生成新的数据样本，大语言模型是生成式模型在自然语言处理领域的应用。
Transformer架构解析：Transformer架构的核心是自注意力机制，能够有效处理序列数据。
预训练、SFT、RLHF：预训练是大模型训练的第一步，SFT和RLHF是进一步优化模型性能的方法。
第三阶段：编程基础与工具使用
Python编程基础：掌握Python的基本语法和数据结构，如列表、字典、函数等。
Python常用库和工具：熟悉Numpy、Pandas等库的使用，掌握TensorFlow和PyTorch等深度学习框架的基本用法。
提示工程基础：提示工程是通过设计合适的提示词来提高模型性能的技术，掌握提示词的常见结构和模版化方法。
第四阶段：实战项目与案例分析
实战项目一：基于提示工程的代码生成，通过设计合适的提示词，让模型生成代码。
实战项目二：基于大模型的文档智能助手，利用大模型的自然语言处理能力，实现文档的智能分析和处理。
实战项目三：基于大模型的医学命名实体识别系统，利用大模型的序列标注能力，实现医学文本中的命名实体识别。
案例分析：通过分析实战项目的实现过程和结果，总结经验教训，提高项目开发能力。
第五阶段：高级应用开发
大模型API应用开发：学习如何使用大模型API进行应用开发，如调用ChatGPT等模型的API。
RAG (Retrieval-Augmented Generation)：了解基于检索增强的生成技术，提高生成内容的准确性和相关性。
向量检索与向量数据库：掌握向量检索技术，了解向量数据库的应用，如Milvus等。
LangChain、Agents、AutoGPT：学习大模型在自动化、智能体等领域的应用，如LangChain框架的使用。
第六阶段：模型微调与私有化部署
私有化部署的必要性：私有化部署可以满足数据安全和个性化需求，适用于企业内部应用。
HuggingFace开源社区的使用：学习如何利用HuggingFace开源社区进行模型微调，如使用Transformers库。
模型微调的意义和常见技术：掌握模型微调的方法和技巧，如LoRA等参数高效微调技术。
第七阶段：前沿技术探索
多模态模型：了解多模态模型的发展现状和应用，如视觉-语言模型。
参数高效微调技术：学习参数高效微调的方法，如LoRA、QLoRA等，提高模型训练效率。
深度学习框架比较：对比分析不同深度学习框架的特点和适用场景，如PyTorch、TensorFlow等。
大模型评估和benchmarking：掌握大模型评估方法，了解行业benchmarking标准，如GLUE、SuperGLUE等。
